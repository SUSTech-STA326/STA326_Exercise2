{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c92a6ba5-2f8d-49a8-9331-7701dd2dcc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b537430-01ca-462e-9196-cdde9204cb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'authority': 'arxiv.org',\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "    'cache-control': 'no-cache',\n",
    "    'sec-ch-ua': '\"Not A(Brand\";v=\"99\", \"Microsoft Edge\";v=\"121\", \"Chromium\";v=\"121\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "    'sec-fetch-dest': 'document',\n",
    "    'sec-fetch-mode': 'navigate',\n",
    "    'sec-fetch-site': 'cross-site',\n",
    "    'sec-fetch-user': '?1',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'}\n",
    "    \n",
    "title_list = []\n",
    "author_list = []\n",
    "subject_list = []\n",
    "abstract_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6548d1b3-f9cd-4f82-9e3c-ebf945e6ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(soup,headers):\n",
    "    \n",
    "    articles = soup.find_all('div', class_='meta')\n",
    "    for article in articles:\n",
    "        \n",
    "        title = article.find('div', class_='list-title mathjax').text.strip()\n",
    "        title = title.replace('Title:', '').strip()\n",
    "        title_list.append(title)\n",
    "        \n",
    "        author = article.find('div', class_='list-authors').text.strip()\n",
    "        author = author.replace('Authors:', '').strip()\n",
    "        author_list.append(author)\n",
    "        \n",
    "        subject = article.find('div', class_='list-subjects').text.strip()\n",
    "        subject = subject.replace('Subjects:', '').strip()\n",
    "        subject_list.append(subject)\n",
    "\n",
    "    links = soup.find_all('a', title='Abstract')\n",
    "\n",
    "    for link in tqdm(links, desc=\"descending\"): \n",
    "        paper_url = \"https://arxiv.org\" + link['href']  \n",
    "        paper_page = requests.get(paper_url, headers=headers)\n",
    "        paper_soup = BeautifulSoup(paper_page.content, 'html.parser')\n",
    "        abstract = paper_soup.find('blockquote', class_='abstract').text.strip()  \n",
    "        abstract = abstract.replace('Abstract:', '').strip()\n",
    "        abstract_list.append(abstract)\n",
    "        \n",
    "    return title_list, author_list, subject_list, abstract_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2ae9858-c0d5-4654-ac26-ff3bcfffe939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "提取进度: 100%|█████████████████████████████████| 25/25 [00:47<00:00,  1.92s/it]\n",
      "提取进度: 100%|█████████████████████████████████| 25/25 [00:19<00:00,  1.30it/s]\n",
      "提取进度: 100%|█████████████████████████████████| 25/25 [00:30<00:00,  1.21s/it]\n",
      "提取进度: 100%|█████████████████████████████████| 25/25 [00:48<00:00,  1.96s/it]\n"
     ]
    }
   ],
   "source": [
    "url = \"https://arxiv.org/list/cs/pastweek?skip=0&show=25\"\n",
    "total_papers = 100  \n",
    "papers_per_page = 25  \n",
    "num_pages = int(total_papers / papers_per_page)\n",
    "\n",
    "for page_num in range(num_pages):\n",
    "    page_url = f\"{url}&skip={page_num * papers_per_page}\"\n",
    "    page = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    scrape_page(soup, headers)\n",
    "\n",
    "    time.sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35f83a47-a2e5-419d-b880-396a7ae33104",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(zip(title_list, author_list, subject_list, abstract_list))\n",
    "data = data[:100]\n",
    "with open('output.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Title', 'Author', 'Subject', 'Abstract'])  # 写入表头\n",
    "    writer.writerows(data) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
