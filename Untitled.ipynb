{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4c13db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本地跑了结果 在服务器上跑太卡了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3033c97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f3b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 请求论文列表的URL\n",
    "url = 'https://arxiv.org/list/cs/pastweek?skip=0&show=100'\n",
    "\n",
    "# 发送HTTP请求获取网页内容\n",
    "response = requests.get(url)\n",
    "web_content = response.text\n",
    "\n",
    "# 使用BeautifulSoup解析网页内容\n",
    "soup = BeautifulSoup(web_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503d96f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 储存的变量们\n",
    "Title = []\n",
    "Author = []\n",
    "Subject = []\n",
    "Abstract = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a7ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper in soup.find_all('div', class_='meta'):\n",
    "    \n",
    "    title = paper.find('div', class_='list-title mathjax').text.strip()\n",
    "    Title.append(title)\n",
    "    authors = [author.text.strip() for author in paper.find_all('div', class_='list-authors')]\n",
    "    Author.append(authors)\n",
    "    subject = paper.find(\"span\", class_='primary-subject').text.strip()\n",
    "    Subject.append(subject)\n",
    "    # 打印论文信息\n",
    "    print(f'Title: {title}')\n",
    "    print(f'Authors: {\", \".join(authors)}')\n",
    "    print(f'Subject: {subject}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6154af3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Abstract= []\n",
    "\n",
    "# 假设每篇论文都被一个'div'包裹，其类名为'arxiv-result'\n",
    "for paper in soup.find_all('span', class_='list-identifier'):\n",
    "    # 根据论文链接来找摘要链接，这里的类名'list-identifier'只是例子，请对照实际情况\n",
    "    abs_link = paper.find('a', title='Abstract')['href']\n",
    "    \n",
    "    # 输出完整的摘要链接\n",
    "    abs_url = f'https://arxiv.org{abs_link}'\n",
    "    print(f'Abstract URL: {abs_url}')\n",
    "    \n",
    "    # 提取标题。这里的'title'和'class-name'需要根据页面实际情况确认\n",
    "    # title = paper.find('div', class_='title').text.strip()\n",
    "    \n",
    "    # 提取作者。这里的'class-name'需要根据页面实际情况确认\n",
    "    # authors = [author.text.strip() for author in paper.find_all('a', class_='author')]\n",
    "    \n",
    "    # 假设我们需要请求摘要页面来获取摘要\n",
    "    abs_response = requests.get(abs_url)\n",
    "    abs_content = abs_response.text\n",
    "    abs_soup = BeautifulSoup(abs_content, 'html.parser')\n",
    "    \n",
    "    # 提取摘要。这里的'class-name'同样需要根据页面实际情况确认\n",
    "    abstract = abs_soup.find('blockquote', class_='abstract mathjax').text.strip()\n",
    "    \n",
    "    Abstract.append(abstract)\n",
    "    \n",
    "    # 打印论文信息\n",
    "    # print(f'Title: {title}')\n",
    "    # print(f'Authors: {\", \".join(authors)}')\n",
    "    print(f'Abstract: {abstract}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9b4fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Author1 = Author\n",
    "Author2 = []\n",
    "for s in Author1:\n",
    "    s = [string.replace('Authors:\\n', '') for string in s]\n",
    "    s = [string.replace('\\n', '') for string in s]\n",
    "    Author2.append(s)\n",
    "\n",
    "cleaned_title = [item.replace('Title:', '') for item in Title]\n",
    "# cleaned_author = [item.replace('title:', '') for item in Author]\n",
    "cleaned_abstract = [item.replace('Abstract:', '') for item in Abstract]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c9c9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_title = [item.replace('Title:', '') for item in Title]\n",
    "# cleaned_author = [item.replace('title:', '') for item in Author]\n",
    "cleaned_abstract = [item.replace('Abstract:', '') for item in Abstract]\n",
    "\n",
    "data = {\n",
    "    'Title': cleaned_title,\n",
    "    'Author': Author2,\n",
    "    'Subject': Subject,\n",
    "    \"Abstract\":cleaned_abstract\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ef8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b3857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
