{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests  # send request\n",
    "from bs4 import BeautifulSoup  # parse web pages\n",
    "import pandas as pd  # csv\n",
    "from time import sleep  # wait\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a request header (to prevent anti-scraping)\n",
    "headers = {\n",
    "    'authority': 'curlconverter.com',\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'accept-language': 'zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6',\n",
    "    'cache-control': 'max-age=0',\n",
    "    'if-modified-since': 'Fri, 15 Jul 2022 21:44:42 GMT',\n",
    "    'if-none-match': 'W/\"62d1dfca-3a58\"',\n",
    "    'referer': 'https://curlconverter.com/',\n",
    "    'sec-ch-ua': '\" Not A;Brand\";v=\"99\", \"Chromium\";v=\"102\", \"Microsoft Edge\";v=\"102\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Linux\"',\n",
    "    'sec-fetch-dest': 'document',\n",
    "    'sec-fetch-mode': 'navigate',\n",
    "    'sec-fetch-site': 'cross-site',\n",
    "    'sec-fetch-user': '?1',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.5005.63 Safari/537.36 Edg/102.0.1245.30',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 爬取每个具体网站的id号\n",
    "webid=[]\n",
    "for i in range(5):\n",
    "    url = f\"https://arxiv.org/list/cs/pastweek?skip={(i-1)*25}&show={25*i}\"\n",
    "    web = requests.get(url=url,headers=headers)\n",
    "    soup = BeautifulSoup(web.content,\"html.parser\")\n",
    "\n",
    "    tmp = soup.find_all(\"dt\")\n",
    "    webid = webid+[ele.select_one(\"span a\").get_text().replace(\"arXiv:\",\"\") for ele in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 爬取每个网站上面的具体信息\n",
    "Title=[]\n",
    "Subjects=[]\n",
    "Authors=[]\n",
    "Abstracts=[]\n",
    "\n",
    "for m in tqdm(webid, desc='Scraping ArXiv'):\n",
    "    url= f\"https://arxiv.org/abs/{m}\"\n",
    "    web = requests.get(url=url,headers=headers)\n",
    "    soup = BeautifulSoup(web.content,\"html.parser\")\n",
    "\n",
    "    abstract = soup.select_one(\"blockquote\").get_text().strip().replace(\"Abstract:\",\"\")\n",
    "    subject = soup.select(\"div h1\")[0].getText().replace(\"Computer Science > \",\"\")\n",
    "    title = soup.select(\"div h1\")[1].get_text().replace(\"Title:\",\"\")\n",
    "    authors=[tmp.get_text() for tmp in soup.select(\"div.authors a\")]\n",
    "\n",
    "    Title.append(title)\n",
    "    Subjects.append(subject)\n",
    "    Authors.append(authors)\n",
    "    Abstracts.append(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Abstracts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Point Could Mamba: Point Cloud Learning via St...</td>\n",
       "      <td>Computer Vision and Pattern Recognition</td>\n",
       "      <td>[Tao Zhang, Xiangtai Li, Haobo Yuan, Shunping ...</td>\n",
       "      <td>In this work, for the first time, we demonstra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mitigating Reversal Curse via Semantic-aware P...</td>\n",
       "      <td>Computation and Language</td>\n",
       "      <td>[Qingyan Guo, Rui Wang, Junliang Guo, Xu Tan, ...</td>\n",
       "      <td>While large language models (LLMs) have achiev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An Experimental Study of Low-Latency Video Str...</td>\n",
       "      <td>Multimedia</td>\n",
       "      <td>[Imran Khan, Tuyen X. Tran, Matti Hiltunen, Th...</td>\n",
       "      <td>Low-latency video streaming over 5G has become...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AtP*: An efficient and scalable method for loc...</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>[János Kramár, Tom Lieberum, Rohin Shah, Neel ...</td>\n",
       "      <td>Activation Patching is a method of directly co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural Acceleration of Incomplete Cholesky Pre...</td>\n",
       "      <td>Distributed, Parallel, and Cluster Computing</td>\n",
       "      <td>[Joshua Dennis Booth, Hongyang Sun, Trevor Gar...</td>\n",
       "      <td>The solution of a sparse system of linear equa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Point Could Mamba: Point Cloud Learning via St...   \n",
       "1  Mitigating Reversal Curse via Semantic-aware P...   \n",
       "2  An Experimental Study of Low-Latency Video Str...   \n",
       "3  AtP*: An efficient and scalable method for loc...   \n",
       "4  Neural Acceleration of Incomplete Cholesky Pre...   \n",
       "\n",
       "                                       Subjects  \\\n",
       "0       Computer Vision and Pattern Recognition   \n",
       "1                      Computation and Language   \n",
       "2                                    Multimedia   \n",
       "3                              Machine Learning   \n",
       "4  Distributed, Parallel, and Cluster Computing   \n",
       "\n",
       "                                             Authors  \\\n",
       "0  [Tao Zhang, Xiangtai Li, Haobo Yuan, Shunping ...   \n",
       "1  [Qingyan Guo, Rui Wang, Junliang Guo, Xu Tan, ...   \n",
       "2  [Imran Khan, Tuyen X. Tran, Matti Hiltunen, Th...   \n",
       "3  [János Kramár, Tom Lieberum, Rohin Shah, Neel ...   \n",
       "4  [Joshua Dennis Booth, Hongyang Sun, Trevor Gar...   \n",
       "\n",
       "                                           Abstracts  \n",
       "0  In this work, for the first time, we demonstra...  \n",
       "1  While large language models (LLMs) have achiev...  \n",
       "2  Low-latency video streaming over 5G has become...  \n",
       "3  Activation Patching is a method of directly co...  \n",
       "4  The solution of a sparse system of linear equa...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转化成为dataframe\n",
    "data = {\n",
    "    'Title': Title,\n",
    "    'Subjects': Subjects,\n",
    "    'Authors': Authors,\n",
    "    'Abstracts': Abstracts\n",
    "}\n",
    "\n",
    "# 创建 DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存入csv\n",
    "df.to_csv(\"./CS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
